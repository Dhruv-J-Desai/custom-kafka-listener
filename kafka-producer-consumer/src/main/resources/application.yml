server:
  port: 8080

spring:

  kafka:
    bootstrap-servers: localhost:9092

    # Producer configuration
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all
      retries: 10
      properties:
        enable.idempotence: true
        linger.ms: 5
        batch.size: 32768

    # Consumer baseline (deserializers only; group/topic set via annotation)
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      properties:
        isolation.level: read_committed

# Enterprise starter knobs (from your SDK)
enterprise:
  kafka:
#    consumer:
#      enable-auto-commit: false
#      auto-offset-reset: earliest
#      max-poll-records: 500
#      poll-timeout-ms: 1500
#      backoff-delay-ms: 1000
#      backoff-max-retries: 3

    ingestion:
      # "auto"  -> SDK automatically calls BitemporalIngestionService.process(...)
      #            and ACKs only if ingestion succeeds
      # "manual" -> SDK does nothing extra; app must call process() + ack itself
      mode: auto

  databricks:
    host: adb-2900282841250571.11.azuredatabricks.net
    http-path: /sql/1.0/warehouses/bbb98e34c8ca882c
    token: dapi60be1890ad3a87888f279f5c4c71ca41

#    workspace:
#      create-bronze-if-missing: true     # SDK will create bronze table if missing

    feeds: # âœ… sibling of workspace
#      - name: crm_profiles_scd2
#        topic: ${KAFKA_TOPIC_TRADES:trade-events}
#
#        bronze:
#          table: kafka_data.bronze.crm_customers
#
#        table: kafka_data.silver.crm_customers
#        mode: scd2
#        eventTimeColumn: event_ts
#
#        schema:
#          keyColumns: [ Email ]
#          attributes:
#            - name: Name
#              type: string
#              trackChanges: true
#            - name: PhoneNo
#              type: string
#              trackChanges: true
#            - name: AccountBal
#              type: decimal(18,2)
#              trackChanges: true
#            - name: Country
#              type: string
#              trackChanges: false
#
#        mapping:
#          Email: $.Email | lower | trim
#          Name: $.Name | trim
#          PhoneNo: $.PhoneNo | digits_only
#          AccountBal: $.AccountBal | currency_to_decimal
#          Country: $.Country | upper
#          event_ts: $.LastUpdated | parse_ts("yyyy-MM-dd'T'HH:mm:ss")
#
#        bitemporal:
#          validFromColumn: valid_from
#          validToColumn: valid_to
#          isCurrentColumn: is_current

      - name: trades_scd2
        topic: ${KAFKA_TOPIC_TRADES:trade-events}

        bronze:
          table: kafka_data.bronze.trade_events_raw

        table: kafka_data.silver.client_trade_events
        mode: scd2
        event-time-column: event_ts

        schema:
          key-columns: [ ClientId, Symbol ]
          attributes:
            - name: Quantity
              type: decimal(18,2)
              track-changes: true
            - name: Price
              type: decimal(18,2)
              track-changes: true
            - name: Direction
              type: string
              track-changes: true

        mapping:
          # Your payload log shows lowercase field names and 'validFrom'
          # 2025-11-09 ... payload={"clientId":"C001","symbol":"AAPL","direction":"SELL","quantity":50,"price":199.99,"validFrom":"...Z"}
          ClientId: $.clientId | trim
          Symbol: $.symbol | upper
          Quantity: $.quantity | to_decimal(2)
          Price: $.price | to_decimal(2)
          Direction: $.direction | upper | trim
          event_ts: $.validFrom | parse_ts("yyyy-MM-dd'T'HH:mm:ss.SSSSSS'Z'")

        bitemporal:
          valid-from-column: valid_from
          valid-to-column: valid_to
          is-current-column: is_current

  tracing:
    enabled: true
    tracer-name: enterprise-kafka-consumer
    add-messaging-attributes: true

management:
  endpoints:
    web:
      exposure:
        include: health,info,beans,env
logging:
  level:
    root: INFO
    org.springframework.kafka: INFO
    com.acme: INFO
    org.springframework.boot.autoconfigure: WARN
